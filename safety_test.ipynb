{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from statistics import *\n",
    "import pickle\n",
    "import statistics\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.metrics import auc\n",
    "from scipy import integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"\") ##use your test dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['bookingID','second'],ascending=True)  ## sort values first by booking_id then by seconds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##groupby bookingid then generate a list for each field\n",
    "df = df.groupby(['bookingID']).agg(lambda x: list(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.read_csv('') ## import your test label \n",
    "label = label.sort_values(by = ['bookingID','label'],ascending=True) \n",
    "label = label.drop_duplicates(subset=['bookingID'],keep='last') \n",
    "label = label.set_index('bookingID',drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##join features and labels\n",
    "df_new = pd.concat([df,label],axis=1)\n",
    "df_new = df_new.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reset index, convert bookingid to a column\n",
    "df = df_new.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add resultant_acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_acc = []\n",
    "for i in range(len(df.index.values)):\n",
    "    acc_x = df.iloc[i,:].acceleration_x\n",
    "    acc_y = df.iloc[i,:].acceleration_y\n",
    "    acc_z = df.iloc[i,:].acceleration_z\n",
    "    result_acc.append(np.sqrt(np.square(acc_x) + np.square(acc_y) + np.square(acc_z)))\n",
    "\n",
    "df['result_acceleration'] = result_acc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add resultant_gyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_gyro = []\n",
    "for i in range(len(df.index.values)):\n",
    "    gyro_x = df.iloc[i,:].gyro_x\n",
    "    gyro_y = df.iloc[i,:].gyro_y\n",
    "    gyro_z = df.iloc[i,:].gyro_z\n",
    "    result_gyro.append(np.sqrt(np.square(gyro_x) + np.square(gyro_y) + np.square(gyro_z)))\n",
    "\n",
    "df['result_gyro'] = result_gyro "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add rotation angle for x-axis and y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate_x = []\n",
    "for i in range(len(df.index.values)):\n",
    "    acc_x = df.iloc[i,:].acceleration_x\n",
    "    acc_y = df.iloc[i,:].acceleration_y\n",
    "    acc_z = df.iloc[i,:].acceleration_z\n",
    "    rotate_x.append(np.arctan(acc_y / np.sqrt(np.square(acc_x)+np.square(acc_z))))\n",
    "\n",
    "df['rotate_x'] = rotate_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_sign(list_):\n",
    "    return [-x for x in list_]\n",
    "\n",
    "rotate_y = []\n",
    "\n",
    "for i in range(len(df.index.values)):\n",
    "    acc_x = flip_sign(df.iloc[i,:].acceleration_x)\n",
    "    acc_z = df.iloc[i,:].acceleration_z\n",
    "    rotate_y.append(np.arctan(np.array(acc_x) / np.array(acc_z)))\n",
    "\n",
    "df['rotate_y'] = rotate_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extract features from raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feature_global():\n",
    "    \n",
    "    def __init__ (self, df):\n",
    "        self.df = df \n",
    "        \n",
    "    def sum_(self,field,index):\n",
    "        return sum(np.abs(self.df.iloc[index,:][field]))\n",
    "    \n",
    "    def mean(self,field,index):\n",
    "        return np.mean(self.df.iloc[index,:][field])\n",
    "    \n",
    "    def max_(self,field,index):\n",
    "        return max(self.df.iloc[index,:][field]) \n",
    "    \n",
    "    def iqr(self,field,index):   ## Interquantile range\n",
    "        return np.percentile(self.df.iloc[index,:][field],75) - np.percentile(self.df.iloc[index,:][field],25)     \n",
    "    \n",
    "    def integrate(self,field,index):\n",
    "        integ = auc(self.df.iloc[index,:].second,np.abs(self.df.iloc[index,:][field]))\n",
    "        return integ\n",
    "    \n",
    "    def max_consecutive_increase(self,field,index): ##maximum interval of consecutive increase\n",
    "        list_ = self.df.iloc[index,:][field]\n",
    "        max_increase = 0     \n",
    "        count = 0\n",
    "        for i in range(len(list_)-1):\n",
    "            if list_[i+1] > list_[i]:\n",
    "                count += 1\n",
    "                if count > max_increase:\n",
    "                    max_increase = count\n",
    "            else: \n",
    "                count = 0\n",
    "        return (max_increase + 1)/len(list_)\n",
    "    \n",
    "    def max_consecutive_decrease(self,field,index):##maximum interval of consecutive decrease\n",
    "        list_ = self.df.iloc[index,:][field]\n",
    "        max_decrease = 0     \n",
    "        count = 0\n",
    "        for i in range(len(list_)-1):\n",
    "            if list_[i+1] < list_[i]:\n",
    "                count += 1\n",
    "                if count > max_decrease:\n",
    "                    max_decrease = count\n",
    "            else: \n",
    "                count = 0\n",
    "        return (max_decrease + 1)/len(list_)\n",
    "    \n",
    "    def change(self,field,index):  ## change in time series (return the mean and max)\n",
    "        a = self.df.iloc[index,:][field]\n",
    "        list_ = [(x - a[i-1]) for i, x in enumerate(a)][1:]\n",
    "        return [statistics.mean(list_),max(list_)]      \n",
    "    \n",
    "    def avg_speed(self,index): ## average speed over the total trip\n",
    "        distance = feature_global.integrate(self,'Speed',index)\n",
    "        return distance / self.df.iloc[index,:].second[-1]\n",
    "    \n",
    "    def avg_gyro(self,index): ## average angle rotated over the total trip\n",
    "        rad_dist = feature_global.integrate(self,'result_gyro',index)\n",
    "        return rad_dist / self.df.iloc[index,:].second[-1]\n",
    "        \n",
    "    def bearing(self,index):  ## change in bearing \n",
    "        a = self.df.iloc[index,:]['Bearing']\n",
    "        distance = feature_global.integrate(self,'Speed',index)\n",
    "        diff_bear = []\n",
    "        \n",
    "        for i in range(1,len(a)):  \n",
    "            if a[i]<90 and a[i-1]>270:   ## this is because the bearing has range(0,360), change from 359.9 to 1 is not 358.9 but 360-359.9+1\n",
    "                diff_bear.append(a[i] + 360 - a[i-1])\n",
    "            elif a[i]>270 and a[i-1]<90:\n",
    "                diff_bear.append(a[i-1] + 360 - a[i])\n",
    "            else:\n",
    "                diff_bear.append(a[i] - a[i-1])\n",
    "        \n",
    "        return [statistics.mean(diff_bear), max(diff_bear), sum(diff_bear)/distance ] ##return mean, max, change in bearing per distance travelled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_mean = []\n",
    "acc_max = []\n",
    "acc_iqr = []\n",
    "acc_increase = []\n",
    "acc_decrease = []\n",
    "acc_mean_diff = []\n",
    "acc_max_diff = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate_x_max = []\n",
    "rotate_x_max_diff = []\n",
    "rotate_x_dist = []\n",
    "\n",
    "rotate_y_max = []\n",
    "rotate_y_max_diff = []\n",
    "rotate_y_dist = []\n",
    "\n",
    "rotate_z_dist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gyro_mean = []\n",
    "gyro_max = []\n",
    "gyro_iqr = []\n",
    "gyro_increase = []\n",
    "gyro_decrease = []\n",
    "rad_dist = []\n",
    "avg_gyro = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_mean = []\n",
    "speed_max = []\n",
    "speed_iqr = []\n",
    "speed_increase = []\n",
    "speed_decrease = []\n",
    "distance = []\n",
    "avg_speed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bear_increase = []\n",
    "bear_decrease = []\n",
    "bear_mean_diff = []\n",
    "bear_max_diff = []\n",
    "bear_change_per_dist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_len = []\n",
    "\n",
    "features = feature_global(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df.index.values)): \n",
    "\n",
    "    acc_mean.append(features.mean('result_acceleration',i))\n",
    "    acc_max.append(features.max_('result_acceleration',i))\n",
    "    acc_iqr.append(features.iqr('result_acceleration',i))\n",
    "    acc_increase.append(features.max_consecutive_increase('result_acceleration',i))\n",
    "    acc_decrease.append(features.max_consecutive_decrease('result_acceleration',i))\n",
    "    acc_mean_diff.append(features.change('result_acceleration',i)[0])\n",
    "    acc_max_diff.append(features.change('result_acceleration',i)[1])\n",
    "    \n",
    "    gyro_mean.append(features.mean('result_gyro',i))\n",
    "    gyro_max.append(features.max_('result_gyro',i))\n",
    "    gyro_iqr.append(features.iqr('result_gyro',i))\n",
    "    gyro_increase.append(features.max_consecutive_increase('result_gyro',i))\n",
    "    gyro_decrease.append(features.max_consecutive_decrease('result_gyro',i))\n",
    "    avg_gyro.append(features.avg_gyro(i))\n",
    "    rad_dist.append(features.integrate('result_gyro',i))\n",
    "    \n",
    "    bear_increase.append(features.max_consecutive_increase('Bearing',i))\n",
    "    bear_decrease.append(features.max_consecutive_decrease('Bearing',i))\n",
    "    bear_mean_diff.append(features.bearing(i)[0])\n",
    "    bear_max_diff.append(features.bearing(i)[1])\n",
    "    bear_change_per_dist.append(features.bearing(i)[2])\n",
    "    \n",
    "    speed_mean.append(features.mean('Speed',i))\n",
    "    speed_max.append(features.max_('Speed',i))\n",
    "    speed_iqr.append(features.iqr('Speed',i))\n",
    "    speed_increase.append(features.max_consecutive_increase('Speed',i))\n",
    "    speed_decrease.append(features.max_consecutive_decrease('Speed',i))\n",
    "    distance.append(features.integrate('Speed',i))\n",
    "    avg_speed.append(features.avg_speed(i))\n",
    "\n",
    "    rotate_x_max.append(features.max_('rotate_x',i))\n",
    "    rotate_x_max_diff.append(features.change('rotate_x',i)[1])\n",
    "    rotate_x_dist.append(features.integrate('gyro_x',i))\n",
    "\n",
    "    rotate_y_max.append(features.max_('rotate_y',i))\n",
    "    rotate_y_max_diff.append(features.change('rotate_y',i)[1])\n",
    "    rotate_y_dist.append(features.integrate('gyro_y',i))\n",
    "\n",
    "    rotate_z_dist.append(features.integrate('gyro_z',i))\n",
    "\n",
    "\n",
    "    trip_len.append(df.iloc[i,:].second[-1])\n",
    "    \n",
    "    if i % 5000 ==0:\n",
    "        print(i,' out of ',len(df.index.values),' is completed')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rotate_x_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine features into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature = np.c_[list(df.bookingID), list(df.label), acc_mean, \n",
    "                  acc_max,  acc_iqr, acc_increase, acc_decrease, acc_mean_diff,\n",
    "                  acc_max_diff, rotate_x_max, rotate_x_max_diff, rotate_x_dist, rotate_y_max,\n",
    "                  rotate_y_max_diff, rotate_y_dist, rotate_z_dist,gyro_mean, gyro_max, gyro_iqr,\n",
    "                  gyro_increase, gyro_decrease, rad_dist,avg_gyro, speed_mean,  speed_max,\n",
    "                  speed_iqr, speed_increase, speed_decrease, distance, avg_speed,\n",
    "                  bear_increase, bear_decrease,  bear_mean_diff, bear_max_diff,\n",
    "                  bear_change_per_dist, trip_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature = pd.DataFrame(df_feature)\n",
    "df_feature.columns = ['bookingID', 'label', 'acc_mean', \n",
    "                  'acc_max',  'acc_iqr', 'acc_increase', 'acc_decrease', 'acc_mean_diff',\n",
    "                  'acc_max_diff', 'rotate_x_max', 'rotate_x_max_diff', 'rotate_x_dist', 'rotate_y_max',\n",
    "                  'rotate_y_max_diff', 'rotate_y_dist', 'rotate_z_dist','gyro_mean', 'gyro_max', 'gyro_iqr',\n",
    "                  'gyro_increase', 'gyro_decrease', 'rad_dist','avg_gyro', 'speed_mean',  'speed_max',\n",
    "                  'speed_iqr', 'speed_increase', 'speed_decrease', 'distance', 'avg_speed',\n",
    "                  'bear_increase', 'bear_decrease',  'bear_mean_diff', 'bear_max_diff',\n",
    "                  'bear_change_per_dist', 'trip_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature.describe().iloc[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk, the filename is the path of your saved model\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# then use df_feature for model testing\n",
    "df_feature = df_feature.drop(columns=['bookingID'],axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
